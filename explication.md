# üöÄ Explication d√©taill√©e du script `train.py`

## üéØ **Objectif du script**
Le script `train.py` impl√©mente un mod√®le d'intelligence artificielle de type **image-to-image** utilisant l'architecture **U-Net++** avec des fonctionnalit√©s avanc√©es de rectification g√©om√©trique. Il transforme des images d'entr√©e en images de sortie en apprenant les correspondances entre des paires d'images.

---

## üìÅ **Architecture g√©n√©rale**

### **1. Structure des donn√©es**
```
dataset/
‚îú‚îÄ‚îÄ from/          # Images d'entr√©e (sources)
‚îú‚îÄ‚îÄ to/            # Images de sortie (cibles)
‚îú‚îÄ‚îÄ inter/         # Images interm√©diaires g√©n√©r√©es pendant l'entra√Ænement
‚îî‚îÄ‚îÄ results/       # R√©sultats finaux
```

### **2. Flux principal**
```
Images FROM ‚Üí Mod√®le U-Net++ ‚Üí Images TO
     ‚Üì              ‚Üì              ‚Üì
  512x512        Traitement     512x512
   (RGB)         IA avanc√©      (RGB)
```

---

## üß† **Architecture du mod√®le : U-Net++**

### **Composants principaux :**

#### **A. Spatial Transformer Network (STN)**
```python
class SpatialTransformerNetwork(nn.Module)
```
- **R√¥le** : Corrige automatiquement les d√©formations g√©om√©triques
- **Fonctionnement** : 
  - Analyse l'image d'entr√©e
  - Calcule une transformation affine (rotation, translation, √©chelle)
  - Applique la correction g√©om√©trique avant le traitement principal

#### **B. U-Net++ avec connexions denses**
```python
class UNetPP(nn.Module)
```
- **Encodeur** : R√©duit progressivement la taille (512‚Üí256‚Üí128‚Üí64‚Üí32)
- **D√©codeur** : Augmente progressivement la taille (32‚Üí64‚Üí128‚Üí256‚Üí512)
- **Skip connections** : Pr√©serve les d√©tails fins
- **Batch Normalization** : Stabilise l'entra√Ænement
- **Dropout** : √âvite le sur-apprentissage

---

## üìä **Dataset et chargement des donn√©es**

### **ImagePairDataset**
```python
class ImagePairDataset(Dataset):
    def __init__(self, from_dir, to_dir, transform=None):
        self.filenames = sorted(os.listdir(from_dir))  # Ordre alphab√©tique
```

**Fonctionnement :**
1. **Correspondance par nom** : `img_0001.png` dans `from/` ‚Üî `img_0001.png` dans `to/`
2. **Chargement automatique** : PIL charge et convertit en RGB
3. **Transformation** : Conversion en tenseurs PyTorch [0,1]

### **DataLoader**
```python
dataloader = DataLoader(dataset, batch_size=8, shuffle=True)
```
- **Batch size 8** : Traite 8 paires d'images simultan√©ment
- **Shuffle=True** : Ordre al√©atoire √† chaque √©poque pour √©viter le sur-apprentissage
- **Parall√©lisation GPU** : Traitement efficace sur CUDA

---

## üéØ **Fonctions de perte avanc√©es**

### **1. Loss L1 (MAE)**
```python
loss_l1 = l1_criterion(output, target)
```
- **Mesure** : Diff√©rence absolue pixel par pixel
- **Avantage** : Pr√©serve les d√©tails fins

### **2. Perceptual Loss**
```python
class PerceptualLoss(nn.Module):
    def __init__(self):
        vgg = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1).features[:16]
```
- **Principe** : Utilise un r√©seau VGG16 pr√©-entra√Æn√©
- **Mesure** : Similarit√© des caract√©ristiques de haut niveau
- **Avantage** : R√©sultats plus naturels visuellement

### **3. SSIM Loss**
```python
class SSIMLoss(nn.Module):
```
- **Mesure** : Similarit√© structurelle entre images
- **√âvalue** : Luminance, contraste, structure
- **Avantage** : Correspond mieux √† la perception humaine

### **Loss combin√©e**
```python
loss = loss_l1 + 0.1 * loss_perc + 0.1 * loss_ssim
```
- **Pond√©ration** : L1 (poids 1.0), Perceptual (poids 0.1), SSIM (poids 0.1)
- **√âquilibre** : D√©tails fins + naturalit√© visuelle + structure

---

## ‚öôÔ∏è **Processus d'entra√Ænement**

### **1. Initialisation**
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNetPP().to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
```

### **2. Boucle d'entra√Ænement (10 000 √©poques)**
```python
for epoch in range(start_epoch, epochs):
    for idx, (from_img, to_img) in enumerate(dataloader):
```

**√âtapes par batch :**
1. **Chargement** : 8 paires d'images sur GPU
2. **Normalisation** : `to_img_tanh = to_img * 2.0 - 1.0` (pour activation Tanh)
3. **Forward pass** : `output = model(from_img)`
4. **Calcul des pertes** : L1 + Perceptual + SSIM
5. **Backpropagation** : Mise √† jour des poids
6. **Accumulation** : Statistiques pour affichage

### **3. Optimisations GPU**
```python
if device.type == 'cuda':
    with torch.amp.autocast('cuda'):  # Mixed precision
        output = model(from_img)
        loss = ...
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```
- **Mixed Precision** : Utilise FP16 pour acc√©l√©rer l'entra√Ænement
- **Scaler** : √âvite l'underflow num√©rique

---

## üíæ **Syst√®me de checkpoints robuste**

### **Sauvegarde automatique**
```python
if (epoch + 1) % 20 == 0:  # Toutes les 20 √©poques
    checkpoint = {
        'epoch': epoch + 1,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': current_loss,
    }
    torch.save(checkpoint, ckpt_path)
```

### **Gestion intelligente**
- **Limite** : Garde seulement les 3 derniers checkpoints
- **Nettoyage automatique** : Supprime les anciens pour √©conomiser l'espace
- **R√©cup√©ration** : D√©tecte et supprime les checkpoints corrompus

### **Reprise automatique**
```python
if last_ckpt and os.path.exists(last_ckpt):
    checkpoint = torch.load(last_ckpt, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    start_epoch = checkpoint['epoch']
```
- **D√©tection automatique** : Trouve le dernier checkpoint
- **Compatibilit√©** : G√®re les anciens et nouveaux formats
- **Choix utilisateur** : Option pour repartir de z√©ro

---

## üñºÔ∏è **Sauvegarde des r√©sultats**

### **Images interm√©diaires (chaque √©poque)**
```python
if idx == 0:  # Premier batch de l'√©poque
    save_image(output_save.cpu(), f'epoch{epoch+1}_output.png')
    save_image(from_img[0].cpu(), f'epoch{epoch+1}_input.png')
    save_image(to_img[0].cpu(), f'epoch{epoch+1}_target.png')
```
- **Suivi visuel** : Voir l'√©volution du mod√®le
- **Comparaison** : Input ‚Üí Output ‚Üí Target c√¥te √† c√¥te

### **Normalisation pour sauvegarde**
```python
output_save = (output[0] + 1) / 2  # [-1,1] ‚Üí [0,1]
```
- **Conversion** : De l'espace Tanh vers l'espace image standard

---

## üìà **M√©triques et monitoring**

### **Affichage d√©taill√©**
```python
print(f"Epoch {epoch+1}/{epochs}, Total Loss: {running_loss/len(dataset):.4f} | 
       L1: {running_l1/len(dataset):.4f} | 
       Perceptual: {running_perc/len(dataset):.4f} | 
       SSIM: {running_ssim/len(dataset):.4f}")
```

### **Calcul des moyennes**
- **running_loss** : Accumule la perte totale
- **Division par len(dataset)** : Moyenne par image
- **Suivi s√©par√©** : Chaque composante de la perte

---

## üîß **Param√®tres cl√©s**

| Param√®tre | Valeur | Description |
|-----------|--------|-------------|
| **√âpoques** | 10 000 | Nombre total d'it√©rations |
| **Batch size** | 8 | Images trait√©es simultan√©ment |
| **Learning rate** | 1e-3 | Taux d'apprentissage Adam |
| **Checkpoints** | Toutes les 20 √©poques | Fr√©quence de sauvegarde |
| **R√©tention** | 3 derniers | Nombre de checkpoints gard√©s |
| **R√©solution** | 512√ó512 | Taille des images d'entr√©e/sortie |

---

## üöÄ **Workflow complet**

1. **Pr√©paration** : Images crop√©es ‚Üí `dataset/from` et `dataset/to`
2. **Initialisation** : Chargement du mod√®le/checkpoint
3. **Entra√Ænement** : 10 000 √©poques avec loss combin√©e
4. **Monitoring** : Sauvegarde d'images + m√©triques
5. **Checkpoints** : Sauvegarde r√©guli√®re + nettoyage
6. **R√©sultats** : Images g√©n√©r√©es dans `dataset/inter`

---

## üéØ **Objectif final**
Apprendre une fonction de transformation **f: FROM ‚Üí TO** qui peut g√©n√©raliser √† de nouvelles images non vues pendant l'entra√Ænement, en pr√©servant les d√©tails fins tout en produisant des r√©sultats visuellement naturels.
